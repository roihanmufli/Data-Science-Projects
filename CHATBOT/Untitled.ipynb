{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bb5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14a5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel('dataset.xlsx',sheet_name='main')\n",
    "df_test = pd.read_excel('dataset.xlsx',sheet_name='test')\n",
    "df_user_response = pd.read_excel('dataset.xlsx',sheet_name='Doni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9cef8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, senang bertemu denganmu</td>\n",
       "      <td>CasualGreeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>halo juga</td>\n",
       "      <td>CasualGreeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hai</td>\n",
       "      <td>CasualGreeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>halo</td>\n",
       "      <td>CasualGreeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hai juga</td>\n",
       "      <td>CasualGreeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      response          intent\n",
       "0  Hi, senang bertemu denganmu  CasualGreeting\n",
       "1                    halo juga  CasualGreeting\n",
       "2                         Hai   CasualGreeting\n",
       "3                         halo  CasualGreeting\n",
       "4                     Hai juga  CasualGreeting"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39fd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_intents = df_user_response['intent'].unique().tolist()\n",
    "dict_response = {}\n",
    "\n",
    "for list_intent in list_intents:\n",
    "    dict_response[list_intent] = df_user_response[df_user_response['intent'] == list_intent]['response'].values.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a2ed0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b426e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case\n",
    "# remove digit\n",
    "# remove symbol\n",
    "# tokenization\n",
    "# stemming\n",
    "# repair slangwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4624848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "        \n",
    "    with open('stopwords.json') as f:\n",
    "        stopwords=json.load(f)\n",
    "    \n",
    "    with open('slangwords.json') as f:\n",
    "        slangwords=json.load(f)\n",
    "        \n",
    "    punctuation = string.punctuation + 'â€™'\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # hapus angka\n",
    "    text = text.translate(str.maketrans(string.digits,' '*len(string.digits)))\n",
    "    # hapus tanda baca\n",
    "    text = text.translate(str.maketrans(punctuation,' '*len(punctuation)))\n",
    "    # hapus whitespace\n",
    "    text = text.strip(\" \")\n",
    "    \n",
    "    # repair slangword\n",
    "    slang = []\n",
    "    formal = []\n",
    "    \n",
    "    for slangword in slangwords['slang'].items():\n",
    "        slang.append(slangword[1])\n",
    "\n",
    "    for formalword in slangwords['formal'].items():\n",
    "        formal.append(formalword[1])\n",
    "    text = text.split()\n",
    "    for index,item in enumerate(text):\n",
    "        if item in slang:\n",
    "            slang_index = slang.index(item)\n",
    "            text[index] = formal[slang_index]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    if type(text) == str:\n",
    "        text = text.split()\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # stemming\n",
    "    text = stemmer.stem(text)\n",
    "        \n",
    "    # tokenization\n",
    "#     text = text.split()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0526f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['preprocessed'] = df_train['text'].apply(lambda x:preprocessing(x))\n",
    "df_test['preprocessed'] = df_test['text'].apply(lambda x:preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff8febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(df_train['preprocessed'])\n",
    "\n",
    "with open('tfidf.pickle', 'wb') as tfidf:\n",
    "    pickle.dump(tfidf_vectorizer, tfidf)\n",
    "\n",
    "doc_vec_train = tfidf_vectorizer.transform(df_train['preprocessed'])\n",
    "doc_vec_test = tfidf_vectorizer.transform(df_test['preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927c93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_train = pd.DataFrame(doc_vec_train.toarray().transpose(),\n",
    "                   index=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "df2_test = pd.DataFrame(doc_vec_test.toarray().transpose(),\n",
    "                   index=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ff0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5e9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = le.fit(df_train['intent'])\n",
    "with open('label_encoder.pickle', 'wb') as label_encoder:\n",
    "    pickle.dump(le, label_encoder)\n",
    "    \n",
    "y_train = le.transform(df_train['intent'])\n",
    "y_test = le.transform(df_test['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb0808b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df2_train.transpose()\n",
    "X_test = df2_test.transpose()\n",
    "# y_train = df_train['intent']\n",
    "# y_test = df_test['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c495668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assalamualaikum</th>\n",
       "      <th>bye</th>\n",
       "      <th>domisili</th>\n",
       "      <th>favorite</th>\n",
       "      <th>halo</th>\n",
       "      <th>hello</th>\n",
       "      <th>hi</th>\n",
       "      <th>hobi</th>\n",
       "      <th>jumpa</th>\n",
       "      <th>kenal</th>\n",
       "      <th>makan</th>\n",
       "      <th>malam</th>\n",
       "      <th>mana</th>\n",
       "      <th>nama</th>\n",
       "      <th>pagi</th>\n",
       "      <th>rumah</th>\n",
       "      <th>selamat</th>\n",
       "      <th>siang</th>\n",
       "      <th>sih</th>\n",
       "      <th>sore</th>\n",
       "      <th>suka</th>\n",
       "      <th>tau</th>\n",
       "      <th>temu</th>\n",
       "      <th>there</th>\n",
       "      <th>tinggal</th>\n",
       "      <th>wabarakatuh</th>\n",
       "      <th>warahmatullahi</th>\n",
       "      <th>wei</th>\n",
       "      <th>wey</th>\n",
       "      <th>woi</th>\n",
       "      <th>woy</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assalamualaikum  bye  domisili  favorite  halo  hello   hi  hobi  jumpa  \\\n",
       "0              0.0  0.0       0.0       0.0   0.0    1.0  0.0   0.0    0.0   \n",
       "1              0.0  0.0       0.0       0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "2              0.0  0.0       0.0       0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "3              0.0  0.0       0.0       0.0   0.0    0.0  0.0   0.0    1.0   \n",
       "4              0.0  0.0       0.0       0.0   0.0    0.0  0.0   0.0    0.0   \n",
       "\n",
       "   kenal     makan  malam     mana  nama  pagi     rumah  selamat  siang  sih  \\\n",
       "0    0.0  0.000000    0.0  0.00000   0.0   0.0  0.000000      0.0    0.0  0.0   \n",
       "1    0.0  0.000000    0.0  0.00000   1.0   0.0  0.000000      0.0    0.0  0.0   \n",
       "2    0.0  0.660211    0.0  0.00000   0.0   0.0  0.000000      0.0    0.0  0.0   \n",
       "3    0.0  0.000000    0.0  0.00000   0.0   0.0  0.000000      0.0    0.0  0.0   \n",
       "4    0.0  0.000000    0.0  0.63804   0.0   0.0  0.770003      0.0    0.0  0.0   \n",
       "\n",
       "   sore     suka  tau  temu  there  tinggal  wabarakatuh  warahmatullahi  wei  \\\n",
       "0   0.0  0.00000  0.0   0.0    0.0      0.0          0.0             0.0  0.0   \n",
       "1   0.0  0.00000  0.0   0.0    0.0      0.0          0.0             0.0  0.0   \n",
       "2   0.0  0.75108  0.0   0.0    0.0      0.0          0.0             0.0  0.0   \n",
       "3   0.0  0.00000  0.0   0.0    0.0      0.0          0.0             0.0  0.0   \n",
       "4   0.0  0.00000  0.0   0.0    0.0      0.0          0.0             0.0  0.0   \n",
       "\n",
       "   wey  woi  woy  you  \n",
       "0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3a112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of rows of training data: 41, the number of columns of training data: 32\n",
      "the number of rows of testing data: 11, the number of columns of testing data: 32\n"
     ]
    }
   ],
   "source": [
    "print(f'the number of rows of training data: {X_train.shape[0]}, the number of columns of training data: {X_train.shape[1]}')\n",
    "print(f'the number of rows of testing data: {X_test.shape[0]}, the number of columns of testing data: {X_test.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db17e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelrf = RandomForestClassifier(class_weight='balanced',random_state=10)\n",
    "modelrf.fit(X_train, y_train)\n",
    "\n",
    "## save model\n",
    "with open('model_rf.pickle', 'wb') as model:\n",
    "    pickle.dump(modelrf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46e4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = modelrf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff7e5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "AfternoonGreeting       1.00      1.00      1.00         1\n",
      "   CasualGreeting       1.00      1.00      1.00         1\n",
      "  EveningGreeting       1.00      1.00      1.00         1\n",
      "     FavoriteFood       1.00      1.00      1.00         1\n",
      "          GoodBye       1.00      1.00      1.00         1\n",
      "            Hobby       1.00      1.00      1.00         1\n",
      "     Introduction       1.00      1.00      1.00         1\n",
      "  IslamicGreeting       1.00      1.00      1.00         1\n",
      "  MorningGreeting       1.00      1.00      1.00         1\n",
      "    NightGreeting       1.00      1.00      1.00         1\n",
      "        Residence       1.00      1.00      1.00         1\n",
      "\n",
      "         accuracy                           1.00        11\n",
      "        macro avg       1.00      1.00      1.00        11\n",
      "     weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names=np.unique(le.inverse_transform(y_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e659f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You : kenalan dong\n",
      "Bot :  kamu bisa panggil aku Doni\n",
      "You : suka makan apa\n",
      "Bot :  aku suka ayam goreng\n",
      "You : ikan suka \n",
      "Bot : Maaf saya tidak mengerti apa maksud kamu\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    texts_p = []\n",
    "    prediction_input = input('You : ')\n",
    "\n",
    "    #removing punctuation and converting to lowercase\n",
    "    prediction_input = preprocessing(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    tf_idf = tfidf_vectorizer.transform(texts_p)\n",
    "    output = modelrf.predict_proba(tf_idf.toarray())[0]\n",
    "    output_index = np.argmax(output)\n",
    "#     print(max(output))\n",
    "    if output[output_index] < 0.63:\n",
    "        print('Bot : Maaf saya tidak mengerti apa maksud kamu')\n",
    "        break\n",
    "    #finding the right tag and predicting\n",
    "    response_tag = np.unique(le.inverse_transform(y_train))[output_index]\n",
    "    print(\"Bot : \",random.choice(dict_response[response_tag]))\n",
    "    if response_tag == \"GoodBye\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7d24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786f5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f64514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b17e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e63210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd77791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
